# Home-Sales---Spark-SQL
Use SparkSQL to determine key metrics about home sales data. Then use Spark to create temporary views, partition the data, cache and uncache a temporary table, and verify that the table has been uncached. Using Google Colab to work on Big Data queries with PySpark SQL, parquet, and cache partitions.
